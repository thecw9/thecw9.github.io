---
title: 文献阅读
top: true
summary: "阅读文献"
---

## Application

##### Anidjar O H, Barak A, Ben-Moshe B, et al. A Stethoscope for Drones: Transformers-Based Methods for UAVs Acoustic Anomaly Detection[J]. IEEE Access, 2023, 11: 33336-33353.

- 这篇文章的主要研究方向是利用声音波浪信号来检测无人机(UAVs)的异常行为。为了解决无人机异常检测的问题，文章提出了一种实时检测无人机异常行为的深度学习框架。该框架使用了一种混合深度学习 Transformer 和 Convolutional Neural Network 的结构，对来自单个麦克风设置的实时音频数据进行处理。该方法使用了 Wav2Vec2 Transformer 模型将原始音频数据转换为图像形式，然后利用 VGG 的 CNN 结构对结果进行分类。该方法可用于无人机航班数据的不同语境下的异常检测，使用 F1-Score 对模型的性能进行衡量。实验结果表明，与使用单一 CNN 模型的方法相比，使用混合模型的方法取得了更好的性能表现，并且拥有更好的鲁棒性。此外，作者提出了 Wav2BC+框架，该框架融合了 Transformer 和 CNN 模型，通过减少 CNN 模型中的参数数量，并保持高准确度，进一步优化了无人机异常检测的性能。 文章还提出了一些未来的方向，例如解决外部噪音问题，通过对不同类型的异常进行分类等。

##### Yu D, Zhang W, Wang H. Research on Transformer Voiceprint Anomaly Detection Based on Data-Driven[J]. Energies, 2023, 16(5): 2151.

- 这篇论文的主要内容是提出了一种基于声波识别变压器异常的方法，使用 Mel-frequency cepstral coefficients（MFCC）、卷积神经网络（CNN）、长短时记忆网络（LSTM）和注意力机制结合的混合声纹识别模型来检测和诊断变压器异常。该模型通过处理声波信号特征向量检测三种状况：正常，在过载状态、放电状态下的变压器。该研究论文的结果显示，注意力-CNN-LSTM 混合模型可以用于变压器的状态声波检测，识别三种状态可以达到超过 99%的准确率。因此，在变压器故障实时检测方面具有较高应用价值。
- 提出了一种基于音频数据的变压器异常诊断方法，使用深度学习模型 Attention-CNN-LSTM 和 Mel 频率倒谱系数（MFCC）来诊断变压器的工作状态。通过对声音信号进行预处理和特征提取，将特征向量输入到 Attention-CNN-LSTM 混合模型中进行训练和异常检测。实验验证表明，Attention-CNN-LSTM 模型在识别变压器状态方面的表现很好，实现了超过 99%的识别精度。该方法提高了异常诊断的准确性和效率，对于变压器的健康状态监测具有一定的实用价值。

##### Jeong Y, Yang E, Ryu J H, et al. AnomalyBERT: Self-Supervised Transformer for Time Series Anomaly Detection using Data Degradation Scheme[J]. arXiv preprint arXiv:2305.04468, 2023.

## Base Model

### GAN

##### Goodfellow I, Pouget-Abadie J, Mirza M, et al. Generative adversarial networks[J]. Communications of the ACM, 2020, 63(11): 139-144.

- 本文介绍了一种新的框架，称为生成对抗网络（Generative Adversarial Nets, GANs）。该框架通过训练两个模型：一个生成模型 G 和一个判别模型 D，用对抗的方式来估计生成模型并捕捉数据的分布。具体而言，G 试图生成与训练数据相似的样本，而 D 试图区分生成的样本与训练数据样本的不同之处。作者在理论上证明了 GANs 的有效性，并使用多个数据集对生成样本进行了定性和定量评估。此外，作者还介绍了 GANs 如何扩展到条件生成模型、学习近似推断、建模所有条件和半监督学习等领域，并探讨了 GANs 的优势和不足之处。

##### Pascual S, Bonafonte A, Serra J. SEGAN: Speech enhancement generative adversarial network[J]. arXiv preprint arXiv:1703.09452, 2017.

### ResNet

##### He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.

### Seq2seq

##### Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural networks[J]. Advances in neural information processing systems, 2014, 27.

### Attention

##### Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate[J]. arXiv preprint arXiv:1409.0473, 2014.

### Transformer

##### Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[J]. Advances in neural information processing systems, 2017, 30.

## Anomaly Detection

##### Han S, Hu X, Huang H, et al. Adbench: Anomaly detection benchmark[J]. Advances in Neural Information Processing Systems, 2022, 35: 32142-32159.

##### DeVries T, Taylor G W. Learning confidence for out-of-distribution detection in neural networks[J]. arXiv preprint arXiv:1802.04865, 2018.

##### Lee K, Lee H, Lee K, et al. Training confidence-calibrated classifiers for detecting out-of-distribution samples[J]. arXiv preprint arXiv:1711.09325, 2017.

##### Kliger M, Fleishman S. Novelty detection with gan[J]. arXiv preprint arXiv:1802.10560, 2018.

##### Scholkopf B, Williamson R, Smola A, et al. Support vector method for novelty detection[J]. Advances in neural information processing systems, 2000, 12(3): 582-588.
