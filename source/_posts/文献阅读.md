---
title: 文献阅读
top: true
#password: "25e64fad465632170b7629e329c1061ff8c2cfb7d16c1c838d529617ced0b1d1"
summary: "阅读文献"
tag: Anomalous sound detection, Anomaly detection
---

## Application

| 名字 | 作者                                      | 题目                                                                                        | 期刊        | 发表年份 | 链接                                                                  |
| ---- | ----------------------------------------- | ------------------------------------------------------------------------------------------- | ----------- | -------- | --------------------------------------------------------------------- |
|      | Anidjar O H, Barak A, Ben-Moshe B, et al. | A Stethoscope for Drones: Transformers-Based Methods for UAVs Acoustic Anomaly Detection[J] | IEEE Access | 2023     | [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10083087) |

> 这篇文章的主要研究方向是利用声音波浪信号来检测无人机(UAVs)的异常行为。为了解决无人机异常检测的问题，文章提出了一种实时检测无人机异常行为的深度学习框架。该框架使用了一种混合深度学习 Transformer 和 Convolutional Neural Network 的结构，对来自单个麦克风设置的实时音频数据进行处理。该方法使用了 Wav2Vec2 Transformer 模型将原始音频数据转换为图像形式，然后利用 VGG 的 CNN 结构对结果进行分类。该方法可用于无人机航班数据的不同语境下的异常检测，使用 F1-Score 对模型的性能进行衡量。实验结果表明，与使用单一 CNN 模型的方法相比，使用混合模型的方法取得了更好的性能表现，并且拥有更好的鲁棒性。此外，名字提出了 Wav2BC+框架，该框架融合了 Transformer 和 CNN 模型，通过减少 CNN 模型中的参数数量，并保持高准确度，进一步优化了无人机异常检测的性能。 文章还提出了一些未来的方向，例如解决外部噪音问题，通过对不同类型的异常进行分类等。

| 名字 | 作者                   | 题目                                                                         | 期刊      | 发表年份 | 链接 |
| ---- | ---------------------- | ---------------------------------------------------------------------------- | --------- | -------- | ---- |
|      | Yu D, Zhang W, Wang H. | Research on Transformer Voiceprint Anomaly Detection Based on Data-Driven[J] | Energies, | 2023     |      |

> 这篇论文的主要内容是提出了一种基于声波识别变压器异常的方法，使用 Mel-frequency cepstral coefficients（MFCC）、卷积神经网络（CNN）、长短时记忆网络（LSTM）和注意力机制结合的混合声纹识别模型来检测和诊断变压器异常。该模型通过处理声波信号特征向量检测三种状况：正常，在过载状态、放电状态下的变压器。该研究论文的结果显示，注意力-CNN-LSTM 混合模型可以用于变压器的状态声波检测，识别三种状态可以达到超过 99%的准确率。因此，在变压器故障实时检测方面具有较高应用价值。

> 提出了一种基于音频数据的变压器异常诊断方法，使用深度学习模型 Attention-CNN-LSTM 和 Mel 频率倒谱系数（MFCC）来诊断变压器的工作状态。通过对声音信号进行预处理和特征提取，将特征向量输入到 Attention-CNN-LSTM 混合模型中进行训练和异常检测。实验验证表明，Attention-CNN-LSTM 模型在识别变压器状态方面的表现很好，实现了超过 99%的识别精度。该方法提高了异常诊断的准确性和效率，对于变压器的健康状态监测具有一定的实用价值。

## Base Model

### GNN

| 名字 | 作者                                          | 题目                                              | 期刊    | 发表年份 | 链接                                                                              |
| ---- | --------------------------------------------- | ------------------------------------------------- | ------- | -------- | --------------------------------------------------------------------------------- |
|      | Sanchez-Lengeling B, Reif E, Pearce A, et al. | A gentle introduction to graph neural networks[J] | Distill | 2021     | [Distill](https://staging.distill.pub/2021/gnn-intro/?ref=https://githubhelp.com) |

> 以详细和直观的方式解释了图神经网络的组件,架构选择,以及这些选择对性能的影响。它使读者能够对图神经网络有一个全面的理解,为使用这类模型解决各种图学习问题打下基础。这篇文章对于想要入门图神经网络的研究人员和从业者具有很好的指导意义。

### AutoEncoder

| 名字        | 作者                           | 题目                                                        | 期刊    | 发表年份 | 链接                                                                  |
| ----------- | ------------------------------ | ----------------------------------------------------------- | ------- | -------- | --------------------------------------------------------------------- |
| AutoEncoder | Hinton G E, Salakhutdinov R R. | Reducing the dimensionality of data with neural networks[J] | science | 2006     | [link](https://dbirman.github.io/learn/hierarchy/pdfs/Hinton2006.pdf) |

> Hinton 等人[2]采用梯度下降来逐层优化 RBM 从而实现对原始样本/特征的抽象表示，并在特征降维上取得显著效果。这才使得采用神经网络来构建 AutoEncoder 的方法得到广泛关注。
> 这篇文章使用的编码器架构是受限玻尔兹曼机，Hinton在2012年的一篇论文中偷偷下了一个结论：玻尔兹曼机是没有什么必要的。

| 名字                  | 作者                                      | 题目                                                                    | 期刊                                                                 | 发表年份 | 链接                                                  |
| --------------------- | ----------------------------------------- | ----------------------------------------------------------------------- | -------------------------------------------------------------------- | -------- | ----------------------------------------------------- |
| Denoising Autoencoder | Vincent P, Larochelle H, Bengio Y, et al. | Extracting and composing robust features with denoising autoencoders[C] | Proceedings of the 25th international conference on Machine learning | 2008     | [sci-hub](https://sci-hub.se/10.1145/1390156.1390294) |

#### Feature Disentangle

| 名字 | 作者                  | 题目                                                                                                                       | 期刊 | 发表年份                                  | 链接 |
| ---- | --------------------- | -------------------------------------------------------------------------------------------------------------------------- | ---- | ----------------------------------------- | ---- |
|      | Chou J, Yeh C, Lee H. | One-shot voice conversion by separating speaker and content representations with instance normalization[J]. arXiv preprint | 2019 | [arxiv](https://arxiv.org/pdf/1904.05742) |

| 名字 | 作者                         | 题目                                                                                                                                | 期刊 | 发表年份                                  | 链接 |
| ---- | ---------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- | ---- | ----------------------------------------- | ---- |
|      | Chou J, Yeh C, Lee H, et al. | Multi-target voice conversion without parallel data by adversarially learning disentangled audio representations[J]. arXiv preprint | 2018 | [arxiv](https://arxiv.org/pdf/1804.02812) |

| 名字   | 作者                             | 题目                                                                                                               | 期刊 | 发表年份 | 链接                                                         |
| ------ | -------------------------------- | ------------------------------------------------------------------------------------------------------------------ | ---- | -------- | ------------------------------------------------------------ |
| AUTOVC | Qian K, Zhang Y, Chang S, et al. | Autovc: Zero-shot voice style transfer with only autoencoder loss[C]//International Conference on Machine Learning | PMLR | 2019     | [link](http://proceedings.mlr.press/v97/qian19c/qian19c.pdf) |

| 名字  | 作者                       | 题目                                       | 期刊                                              | 发表年份 | 链接                                                                                              |
| ----- | -------------------------- | ------------------------------------------ | ------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------- |
| VQVAE | Van Den Oord A, Vinyals O. | Neural discrete representation learning[J] | Advances in neural information processing systems | 2017     | [link](https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf) |

| 名字 | 作者                   | 题目                               | 期刊           | 发表年份 | 链接                                                                                    |
| ---- | ---------------------- | ---------------------------------- | -------------- | -------- | --------------------------------------------------------------------------------------- |
| VAE  | Kingma D P, Welling M. | Auto-encoding variational bayes[J] | arXiv preprint | 2013     | [link](https://arxiv.org/pdf/1312.6114.pdf?source=post_page---------------------------) |

| 名字 | 作者                        | 题目                                                | 期刊                                                                              | 发表年份 | 链接                                                                                                                                 |
| ---- | --------------------------- | --------------------------------------------------- | --------------------------------------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| MAE  | He K, Chen X, Xie S, et al. | Masked autoencoders are scalable vision learners[C] | Proceedings of the IEEE/CVF conference on computer vision and pattern recognition | 2022     | [link](http://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf) |

### Voice Conversion

| 名字 | 作者                         | 题目                                                                                        | 期刊                                                        | 发表年份 | 链接                                                                            |
| ---- | ---------------------------- | ------------------------------------------------------------------------------------------- | ----------------------------------------------------------- | -------- | ------------------------------------------------------------------------------- |
|      | Toda T, Black A W, Tokuda K. | Voice conversion based on maximum-likelihood estimation of spectral parameter trajectory[J] | IEEE Transactions on Audio, Speech, and Language Processing | 2007     | [link](http://ayesha.lti.cs.cmu.edu/mlsp/courses/fall2013/lectures/Toda_VC.pdf) |

### 生成模型

| 名字 | 作者                                           | 题目                               | 期刊                      | 发表年份 | 链接 |
| ---- | ---------------------------------------------- | ---------------------------------- | ------------------------- | -------- | ---- |
| GAN  | Goodfellow I, Pouget-Abadie J, Mirza M, et al. | Generative adversarial networks[J] | Communications of the ACM | 2020     |      |

> 本文介绍了一种新的框架，称为生成对抗网络（Generative Adversarial Nets, GANs）。该框架通过训练两个模型：一个生成模型 G 和一个判别模型 D，用对抗的方式来估计生成模型并捕捉数据的分布。具体而言，G 试图生成与训练数据相似的样本，而 D 试图区分生成的样本与训练数据样本的不同之处。名字在理论上证明了 GANs 的有效性，并使用多个数据集对生成样本进行了定性和定量评估。此外，作者还介绍了 GANs 如何扩展到条件生成模型、学习近似推断、建模所有条件和半监督学习等领域，并探讨了 GANs 的优势和不足之处。

| 名字 | 作者                 | 题目                                       | 期刊           | 发表年份 | 链接                                                              |
| ---- | -------------------- | ------------------------------------------ | -------------- | -------- | ----------------------------------------------------------------- |
| CGAN | Mirza M, Osindero S. | Conditional generative adversarial nets[J] | arXiv preprint | 2014     | [link](https://arxiv.org/pdf/1411.1784.pdf%EF%BC%88CGAN%EF%BC%89) |

> 在原有的对抗生成网络框架下,提出了条件对抗生成网络。相比无条件的对抗生成网络,条件对抗生成网络可以通过给生成器和判别器添加条件信息来控制数据生成过程。

| 名字  | 作者                       | 题目                                             | 期刊                                                                 | 发表年份 | 链接                                                                                                            |
| ----- | -------------------------- | ------------------------------------------------ | -------------------------------------------------------------------- | -------- | --------------------------------------------------------------------------------------------------------------- |
| LSGAN | Mao X, Li Q, Xie H, et al. | Least squares generative adversarial networks[C] | Proceedings of the IEEE international conference on computer vision. | 2017     | [link](https://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf) |

> 1. 提出了LSGAN,其判别器采用最小二乘损失函数,而不是常规GAN中的sigmoid交叉熵损失函数。作者指出sigmoid交叉熵损失函数会导致生成的样本即使在判别器正确的一侧但远离真实数据时梯度消失的问题。而最小二乘损失能惩罚这些样本,使其向判别边界移动。
> 2. 证明了最小化LSGAN的目标函数等价于最小化真实分布与生成分布的Pearson χ2散度。而常规GAN最小化的 Jensen-Shannon散度。

| 名字 | 作者                                        | 题目                                     | 期刊                                              | 发表年份 | 链接                                                                                                              |
| ---- | ------------------------------------------- | ---------------------------------------- | ------------------------------------------------- | -------- | ----------------------------------------------------------------------------------------------------------------- |
|      | Salimans T, Goodfellow I, Zaremba W, et al. | Improved techniques for training gans[J] | Advances in neural information processing systems | 2016     | [link](https://proceedings.neurips.cc/paper_files/paper/2016/hash/8a3363abe792db2d8761d6403605aeb7-Abstract.html) |

> 特征匹配（Feature Matching）解决了生成对抗网络（GAN）因过度训练判别器响应而导致的不稳定性问题。在特征匹配技术中，用于优化生成器的目标函数被调整以改善 GAN 的训练。不再通过最大化判别器对生成样本的输出来优化生成器的参数，而是强制生成器生成具有与训练数据相似统计特性的数据，即其中间特征表示与真实图像的特征表示相似。

| 名字 | 作者                              | 题目                                                                                         | 期刊 | 发表年份 | 链接                                                       |
| ---- | --------------------------------- | -------------------------------------------------------------------------------------------- | ---- | -------- | ---------------------------------------------------------- |
| WGAN | Arjovsky M, Chintala S, Bottou L. | Wasserstein generative adversarial networks[C]//International conference on machine learning | PMLR | 2017     | [link](https://proceedings.mlr.press/v70/arjovsky17a.html) |

> 提出了一种新的GAN算法,称为Wasserstein GAN(WGAN)，它使用Wasserstein距离（也称为地球移动距离）作为将生成分布与真实分布之间的距离刻画的测度，而不是传统GAN中使用的KL散度或JS散度。Wasserstein距离能够更好地度量分布之间的差异，尤其适用于处理维度较低的流形上的分布。

| 名字    | 作者                                     | 题目                                     | 期刊                                              | 发表年份 | 链接                                                                                                              |
| ------- | ---------------------------------------- | ---------------------------------------- | ------------------------------------------------- | -------- | ----------------------------------------------------------------------------------------------------------------- |
| WGAN-GP | Gulrajani I, Ahmed F, Arjovsky M, et al. | Improved training of wasserstein gans[J] | Advances in neural information processing systems | 2017     | [link](https://proceedings.neurips.cc/paper_files/paper/2017/hash/892c3b1c6dccd52936e27cbd0ff683d6-Abstract.html) |

| 名字   | 作者                                  | 题目                                                          | 期刊           | 发表年份 | 链接                                     |
| ------ | ------------------------------------- | ------------------------------------------------------------- | -------------- | -------- | ---------------------------------------- |
| SN-GAN | Miyato T, Kataoka T, Koyama M, et al. | Spectral normalization for generative adversarial networks[J] | arXiv preprint | 2018     | [link](https://arxiv.org/abs/1802.05957) |

| 名字  | 作者                           | 题目                                                                                            | 期刊           | 发表年份 | 链接                                            |
| ----- | ------------------------------ | ----------------------------------------------------------------------------------------------- | -------------- | -------- | ----------------------------------------------- |
| DCGAN | Radford A, Metz L, Chintala S. | Unsupervised representation learning with deep convolutional generative adversarial networks[J] | arXiv preprint | 2015     | [arxiv](https://arxiv.org/pdf/1511.06434v2.pdf) |

| 名字             | 作者                                     | 题目                                                                                                                             | 期刊                                                                                                     | 发表年份 | 链接                                                                                              |
| ---------------- | ---------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------- |
| SEGAN            | Pascual S, Bonafonte A, Serra J.         | SEGAN: Speech enhancement generative adversarial network[J]                                                                      | arXiv preprint                                                                                           | 2017     |                                                                                                   |
| WaveGAN          | Donahue C, McAuley J, Puckette M.        | Adversarial audio synthesis[J]                                                                                                   | arXiv preprint                                                                                           | 2018     | [arxiv](https://arxiv.org/pdf/1802.04208.pdf)                                                     |
| Gansynth         | Engel J, Agrawal K K, Chen S, et al.     | Gansynth: Adversarial neural audio synthesis[J]                                                                                  | arXiv preprint                                                                                           | 2019     | [link](https://arxiv.org/pdf/1902.08710)                                                          |
| MelGAN           | Kumar K, Kumar R, De Boissiere T, et al. | Melgan: Generative adversarial networks for conditional waveform synthesis[J]                                                    | Advances in neural information processing systems                                                        | 2019     | [link](https://proceedings.neurips.cc/paper/2019/file/6804c9bca0a615bdb9374d00a9fcba59-Paper.pdf) |
| Parallel WaveGAN | Yamamoto R, Song E, Kim J M.             | Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram[C] | ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE | 2020     | [arxiv](https://arxiv.org/pdf/1910.11480.pdf)                                                     |
| HiFi-GAN         | Kong J, Kim J, Bae J.                    | Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis[J]                                    | Advances in Neural Information Processing Systems                                                        | 2020     | [link](https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf) |
| Multiband-MelGAN | Yang G, Yang S, Liu K, et al.            | Multi-band melgan: Faster waveform generation for high-quality text-to-speech[C]                                                 | 2021 IEEE Spoken Language Technology Workshop (SLT). IEEE                                                | 2021     | [arxiv](https://arxiv.org/abs/2005.05106)                                                         |
| StyleMelGAN      | Mustafa A, Pia N, Fuchs G.               | Stylemelgan: An efficient high-fidelity adversarial vocoder with temporal adaptive normalization[C]                              | ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE | 2021     | [arxiv](https://arxiv.org/pdf/2011.01557.pdf)                                                     |

Guo Y, Chen Q, Chen J, et al. Auto-embedding generative adversarial networks for high resolution image synthesis[J]. IEEE Transactions on Multimedia, 2019, 21(11): 2726-2737.

| 名字 | 作者                  | 题目                                             | 期刊                                              | 发表年份 | 链接                                                                                                          |
| ---- | --------------------- | ------------------------------------------------ | ------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------------- |
|      | Dhariwal P, Nichol A. | Diffusion models beat gans on image synthesis[J] | Advances in neural information processing systems | 2021     | [link](https://proceedings.neurips.cc/paper_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf) |

### ResNet

| 名字   | 作者                         | 题目                                            | 期刊                                                                          | 发表年份 | 链接 |
| ------ | ---------------------------- | ----------------------------------------------- | ----------------------------------------------------------------------------- | -------- | ---- |
| ResNet | He K, Zhang X, Ren S, et al. | Deep residual learning for image recognition[C] | Proceedings of the IEEE conference on computer vision and pattern recognition | 2016     |      |

### Seq2seq

| 名字 | 作者                            | 题目                                                  | 期刊                                              | 发表年份 | 链接 |
| ---- | ------------------------------- | ----------------------------------------------------- | ------------------------------------------------- | -------- | ---- |
|      | Sutskever I, Vinyals O, Le Q V. | Sequence to sequence learning with neural networks[J] | Advances in neural information processing systems | 2014     |      |

### Attention

| 名字 | 作者                         | 题目                                                                     | 期刊           | 发表年份 | 链接 |
| ---- | ---------------------------- | ------------------------------------------------------------------------ | -------------- | -------- | ---- |
|      | Bahdanau D, Cho K, Bengio Y. | Neural machine translation by jointly learning to align and translate[J] | arXiv preprint | 2014     |      |

### Transformer

| 名字        | 作者                                   | 题目                         | 期刊                                              | 发表年份 | 链接 |
| ----------- | -------------------------------------- | ---------------------------- | ------------------------------------------------- | -------- | ---- |
| Transformer | Vaswani A, Shazeer N, Parmar N, et al. | Attention is all you need[J] | Advances in neural information processing systems | 2017     |      |

### Anomaly Detection

| 名字 | 作者                          | 题目                                             | 期刊                         | 发表年份 | 链接                                      |
| ---- | ----------------------------- | ------------------------------------------------ | ---------------------------- | -------- | ----------------------------------------- |
|      | Pang G, Shen C, Cao L, et al. | Deep learning for anomaly detection: A review[J] | ACM computing surveys (CSUR) | 2021     | [arxiv](https://arxiv.org/pdf/2007.02500) |

| 名字 | 作者                         | 题目                                    | 期刊                                              | 发表年份 | 链接 |
| ---- | ---------------------------- | --------------------------------------- | ------------------------------------------------- | -------- | ---- |
|      | Han S, Hu X, Huang H, et al. | Adbench: Anomaly detection benchmark[J] | Advances in Neural Information Processing Systems | 2022     |      |

| 名字 | 作者                   | 题目                                                                        | 期刊           | 发表年份 | 链接 |
| ---- | ---------------------- | --------------------------------------------------------------------------- | -------------- | -------- | ---- |
|      | DeVries T, Taylor G W. | Learning confidence for out-of-distribution detection in neural networks[J] | arXiv preprint | 2018     |      |

| 名字 | 作者                        | 题目                                                                                    | 期刊           | 发表年份 | 链接 |
| ---- | --------------------------- | --------------------------------------------------------------------------------------- | -------------- | -------- | ---- |
|      | Lee K, Lee H, Lee K, et al. | Training confidence-calibrated classifiers for detecting out-of-distribution samples[J] | arXiv preprint | 2017     |      |

| 名字 | 作者                                       | 题目                                           | 期刊                                              | 发表年份 | 链接 |
| ---- | ------------------------------------------ | ---------------------------------------------- | ------------------------------------------------- | -------- | ---- |
|      | Scholkopf B, Williamson R, Smola A, et al. | Support vector method for novelty detection[J] | Advances in neural information processing systems | 2000     |      |

| 名字 | 作者                              | 题目                                      | 期刊           | 发表年份 | 链接                                     |
| ---- | --------------------------------- | ----------------------------------------- | -------------- | -------- | ---------------------------------------- |
|      | Haloui I, Gupta J S, Feuillard V. | Anomaly detection with Wasserstein GAN[J] | arXiv preprint | 2018     | [link](https://arxiv.org/abs/1812.02463) |

| 名字 | 作者                        | 题目                                                                                   | 期刊           | 发表年份 | 链接 |
| ---- | --------------------------- | -------------------------------------------------------------------------------------- | -------------- | -------- | ---- |
|      | Li D, Chen D, Goh J, et al. | Anomaly detection with generative adversarial networks for multivariate time series[J] | arXiv preprint | 2018     |      |

| 名字   | 作者                                        | 题目                                                                                             | 期刊                                                                                                                                                                        | 发表年份 | 链接                                          |
| ------ | ------------------------------------------- | ------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | --------------------------------------------- |
| AnoGAN | Schlegl T, Seeböck P, Waldstein S M, et al. | Unsupervised anomaly detection with generative adversarial networks to guide marker discovery[C] | Information Processing in Medical Imaging: 25th International Conference, IPMI 2017, Boone, NC, USA, June 25-30, 2017, Proceedings. Cham: Springer International Publishing | 2017     | [[pdf]](https://arxiv.org/pdf/1703.05921.pdf) |

> 这篇文章的主要内容是介绍了一种使用生成对抗网络（GAN）进行无监督异常检测的方法，名为 AnoGAN。创新点主要体现在以下几个方面：
>
> 1. 使用生成对抗网络（GAN）进行表示学习：通过训练一个 GAN 模型，该方法能够学习到正常数据的流形，从而捕捉到正常图像的特征和分布。
> 2. 引入新颖的异常得分方案：该方法通过对图像从图像空间到潜在空间的映射，将图像转化为潜在空间中的表示，并计算图像在潜在空间中的重建误差和在流形上的位置。通过这样的异常得分方案，能够有效地识别出异常图像。
>
> 综上所述，该方法通过利用生成对抗网络进行无监督学习，提出了一种新颖的异常检测方法，并在医学图像数据上进行了实证验证，具有很大的创新和应用潜力。

| 名字  | 作者                                 | 题目                                     | 期刊           | 发表年份 | 链接 |
| ----- | ------------------------------------ | ---------------------------------------- | -------------- | -------- | ---- |
| EGBAD | Zenati H, Foo C S, Lecouat B, et al. | Efficient gan-based anomaly detection[J] | arXiv preprint | 2018     |      |

> 这篇文章的主要内容是利用生成对抗网络（GANs）实现高效的异常检测。作者利用最近发展的GAN模型，在训练过程中学习了一个编码器，从而避免了在测试时进行重建潜在表示的计算密集步骤。

| 名字     | 作者                                        | 题目                                                                                  | 期刊                   | 发表年份 | 链接                                                                   |
| -------- | ------------------------------------------- | ------------------------------------------------------------------------------------- | ---------------------- | -------- | ---------------------------------------------------------------------- |
| f-AnoGAN | Schlegl T, Seeböck P, Waldstein S M, et al. | f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks[J] | Medical image analysis | 2019     | [link](https://sci-hub.se/https://doi.org/10.1016/j.media.2019.01.010) |

> 介绍了一种名为f-AnoGAN的快速无监督异常检测技术，并将其应用于眼底光学相干断层扫描（OCT）图像的异常检测。
>
> 1. 基于GAN的无监督学习：使用生成对抗网络（GAN）训练了一个大规模的正常图像数据集，以捕捉正常数据的变异性。这种无监督学习方法避免了耗时的人工标注过程。
> 2. 编码器训练和异常检测：通过训练编码器将新的图像数据映射到GAN的潜在空间，然后利用判别器特征残差误差和图像重构误差的组合异常得分来检测异常。这种方法可以对图像进行像素级别的异常检测和定位。
> 3. 快速异常检测：f-AnoGAN方法通过将新数据映射到GAN的潜在空间，并使用预训练的编码器进行异常检测，实现了快速的异常检测过程，具有高效性和实用性。
>
> 综上所述，该文章的主要内容是介绍了f-AnoGAN技术的实现及其在眼底OCT图像中的应用。其创新点在于通过GAN的无监督学习和编码器训练实现快速和高效的异常检测，具有较高的准确性和可用性。

| 名字     | 作者                                        | 题目                                                                    | 期刊                                                                                                                                                                               | 发表年份 | 链接                                                                                                    |
| -------- | ------------------------------------------- | ----------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- | ------------------------------------------------------------------------------------------------------- |
| Ganomaly | Akcay S, Atapour-Abarghouei A, Breckon T P. | Ganomaly: Semi-supervised anomaly detection via adversarial training[C] | Computer Vision–ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2–6, 2018, Revised Selected Papers, Part III 14. Springer International Publishing | 2019     | [[arxiv]](https://arxiv.org/pdf/1805.06725)[[sci-hub]](https://sci-hub.se/10.1007/978-3-030-20893-6_39) |

> 提出了一种名为GANomaly的半监督异常检测方法。该方法通过生成器、编码器和判别器三个子网络构成，通过联合学习高维图像空间的生成和潜在空间的推断，来解决高度偏向一个类别（正常）的数据集中检测未知/未见异常情况的问题。

| 名字        | 作者                             | 题目                                                                                                                         | 期刊                                                                                               | 发表年份 | 链接                                                            |
| ----------- | -------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | -------- | --------------------------------------------------------------- |
|             | Pan T, Chen J, Xie J, et al.     | Deep feature generating network: A new method for intelligent fault detection of mechanical systems under class imbalance[J] | IEEE Transactions on Industrial Informatics                                                        | 2020     | [link](https://sci-hub.se/10.1109/TII.2020.3030967)             |
| AnomalyBERT | Jeong Y, Yang E, Ryu J H, et al. | AnomalyBERT: Self-Supervised Transformer for Time Series Anomaly Detection using Data Degradation Scheme[J]                  | arXiv preprint                                                                                     | 2023     |                                                                 |
|             | An J, Cho S.                     | Variational autoencoder based anomaly detection using reconstruction probability[J]                                          | Special lecture on IE                                                                              | 2015     | [link](http://dm.snu.ac.kr/static/docs/TR/SNUDM-TR-2015-03.pdf) |
|             | Zhou C, Paffenroth R C.          | Anomaly detection with robust deep autoencoders[C]                                                                           | Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining | 2017     | [link](http://library.usc.edu.ph/ACM/KKD%202017/pdfs/p665.pdf)  |
| DAGMM       | Zong B, Song Q, Min M R, et al.  | Deep autoencoding gaussian mixture model for unsupervised anomaly detection[C]                                               | International conference on learning representations                                               | 2018     | [link](https://openreview.net/pdf?id=BJJLHbb0-)                 |

#### Open-set recognition

| 名字 | 作者                        | 题目                                                                                    | 期刊           | 发表年份 | 链接                                      |
| ---- | --------------------------- | --------------------------------------------------------------------------------------- | -------------- | -------- | ----------------------------------------- |
|      | DeVries T, Taylor G W.      | Learning confidence for out-of-distribution detection in neural networks[J]             | arXiv preprint | 2018     | [arxiv](https://arxiv.org/pdf/1802.04865) |
|      | Lee K, Lee H, Lee K, et al. | Training confidence-calibrated classifiers for detecting out-of-distribution samples[J] | arXiv preprint | 2017     | [arxiv](https://arxiv.org/pdf/1711.09325) |
|      | Kliger M, Fleishman S.      | Novelty detection with gan[J]                                                           | arXiv preprint | 2018     | [arxiv](https://arxiv.org/pdf/1802.10560) |

#### Datasets

| 名字                        | 作者                                    | 题目                                                                                                                            | 期刊           | 发表年份 | 链接                                                                                          |
| --------------------------- | --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- | -------------- | -------- | --------------------------------------------------------------------------------------------- |
| MIMII DG                    | Dohi K, Nishida T, Purohit H, et al.    | MIMII DG: Sound dataset for malfunctioning industrial machine investigation and inspection for domain generalization task[J]    | arXiv preprint | 2022     | [link](https://arxiv.org/pdf/2205.13879)                                                      |
| ToyADMOS2                   | Harada N, Niizumi D, Takeuchi D, et al. | ToyADMOS2: Another dataset of miniature-machine operating sounds for anomalous sound detection under domain shift conditions[J] | arXiv preprint | 2021     | [link](https://arxiv.org/pdf/2106.02369)                                                      |
| DCASE 2022 Challenge TASK 2 |                                         |                                                                                                                                 |                |          | [link](https://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds) |
